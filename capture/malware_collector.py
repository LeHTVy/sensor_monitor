#!/usr/bin/env python3
"""
Malware Collector Module
Captures, stores, and analyzes files from honeypot attacks
Integrates with existing Kafka pipeline for malware analysis
"""

import os
import json
import hashlib
import magic
import uuid
import zipfile
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, List
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MalwareCollector:
    """
    Captures and safely stores malware samples from honeypot
    Calculates hashes, extracts metadata, and queues for analysis
    """

    def __init__(self, quarantine_path='malware_quarantine'):
        self.quarantine_path = Path(quarantine_path)
        self.setup_quarantine_structure()
        
        # File type categories
        self.file_categories = {
            'executable': ['.exe', '.dll', '.sys', '.drv', '.scr', '.com', '.bat', '.cmd', '.msi'],
            'script': ['.ps1', '.vbs', '.js', '.jar', '.py', '.rb', '.pl', '.sh', '.bash'],
            'document': ['.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.pdf', '.rtf'],
            'archive': ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.cab'],
            'webshell': ['.php', '.jsp', '.asp', '.aspx', '.cgi'],
            'other': []
        }
        
        logger.info(f"‚úÖ Malware Collector initialized")
        logger.info(f"   Quarantine path: {self.quarantine_path.absolute()}")

    def setup_quarantine_structure(self):
        """Create quarantine directory structure"""
        directories = [
            'samples/executables',
            'samples/scripts',
            'samples/documents',
            'samples/archives',
            'samples/webshells',
            'samples/other',
            'metadata',
            'extracted',
            'reports',
            'encrypted_storage'
        ]
        
        for directory in directories:
            path = self.quarantine_path / directory
            path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"üìÅ Quarantine structure created at {self.quarantine_path}")

    def calculate_hashes(self, file_path: str) -> Dict[str, str]:
        """
        Calculate multiple hashes for a file
        
        Args:
            file_path: Path to file
            
        Returns:
            Dictionary with MD5, SHA1, SHA256, SHA512 hashes
        """
        hash_algorithms = {
            'md5': hashlib.md5(),
            'sha1': hashlib.sha1(),
            'sha256': hashlib.sha256(),
            'sha512': hashlib.sha512()
        }
        
        try:
            with open(file_path, 'rb') as f:
                while chunk := f.read(8192):
                    for algo in hash_algorithms.values():
                        algo.update(chunk)
            
            hashes = {
                name: algo.hexdigest() 
                for name, algo in hash_algorithms.items()
            }
            
            logger.debug(f"üî¢ Calculated hashes for {file_path}")
            return hashes
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating hashes: {e}")
            return {}

    def get_file_type(self, file_path: str) -> Dict[str, str]:
        """
        Detect file type using magic bytes and extension
        
        Args:
            file_path: Path to file
            
        Returns:
            Dictionary with mime_type, extension, description
        """
        try:
            # Get MIME type using python-magic
            mime = magic.Magic(mime=True)
            mime_type = mime.from_file(file_path)
            
            # Get detailed description
            mime_desc = magic.Magic()
            description = mime_desc.from_file(file_path)
            
            # Get extension
            extension = Path(file_path).suffix.lower()
            
            # Determine category
            category = self._categorize_file(extension)
            
            return {
                'mime_type': mime_type,
                'extension': extension,
                'description': description,
                'category': category
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error detecting file type: {e}")
            return {
                'mime_type': 'unknown',
                'extension': Path(file_path).suffix.lower(),
                'description': 'Unknown',
                'category': 'other'
            }

    def _categorize_file(self, extension: str) -> str:
        """Categorize file by extension"""
        for category, extensions in self.file_categories.items():
            if extension in extensions:
                return category
        return 'other'

    def collect_file(self, 
                    file_path: str, 
                    source_ip: str,
                    original_filename: str = None,
                    capture_method: str = 'unknown',
                    attack_id: str = None,
                    additional_metadata: Dict = None) -> Optional[Dict]:
        """
        Collect and store a malware sample
        
        Args:
            file_path: Path to the file to collect
            source_ip: IP address of the attacker
            original_filename: Original filename from upload
            capture_method: How the file was captured (file_upload, payload_extraction, download)
            attack_id: Associated attack log ID from Elasticsearch
            additional_metadata: Additional context data
            
        Returns:
            Dictionary with file metadata and storage info
        """
        try:
            if not os.path.exists(file_path):
                logger.error(f"‚ùå File not found: {file_path}")
                return None
            
            # Generate unique file ID
            file_id = str(uuid.uuid4())
            timestamp = datetime.now().isoformat()
            
            # Calculate hashes
            logger.info(f"üî¢ Calculating hashes for {file_path}...")
            hashes = self.calculate_hashes(file_path)
            
            # Detect file type
            logger.info(f"üîç Detecting file type...")
            file_type_info = self.get_file_type(file_path)
            
            # Get file size
            file_size = os.path.getsize(file_path)
            
            # Determine storage category
            category = file_type_info['category']
            
            # Create safe filename using SHA256 hash
            safe_filename = f"{hashes['sha256']}{file_type_info['extension']}"
            storage_path = self.quarantine_path / 'samples' / category / safe_filename
            
            # Copy file to quarantine (don't move, keep original)
            shutil.copy2(file_path, storage_path)
            logger.info(f"üì¶ Stored sample: {storage_path}")
            
            # Create encrypted backup (password-protected ZIP)
            self._create_encrypted_backup(storage_path, hashes['sha256'])
            
            # Build metadata
            metadata = {
                'file_id': file_id,
                'timestamp': timestamp,
                'source_ip': source_ip,
                'original_filename': original_filename or Path(file_path).name,
                'safe_filename': safe_filename,
                'file_size': file_size,
                'hashes': hashes,
                'file_type': file_type_info,
                'capture_method': capture_method,
                'attack_id': attack_id,
                'storage_path': str(storage_path.relative_to(self.quarantine_path)),
                'encrypted_backup': f"encrypted_storage/{hashes['sha256']}.zip",
                'analysis_status': 'pending',
                'yara_scanned': False,
                'sandboxed': False,
                'iocs_extracted': False
            }
            
            # Add additional metadata if provided
            if additional_metadata:
                metadata['additional_info'] = additional_metadata
            
            # Save metadata JSON
            metadata_path = self.quarantine_path / 'metadata' / f"{file_id}.json"
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2)
            
            logger.info(f"‚úÖ Malware sample collected: {file_id}")
            logger.info(f"   SHA256: {hashes['sha256']}")
            logger.info(f"   Type: {file_type_info['mime_type']}")
            logger.info(f"   Size: {file_size:,} bytes")
            
            return metadata
            
        except Exception as e:
            logger.error(f"‚ùå Error collecting file: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None

    def _create_encrypted_backup(self, file_path: Path, sha256_hash: str):
        """
        Create password-protected ZIP backup of sample
        Standard password: 'infected'
        """
        try:
            zip_path = self.quarantine_path / 'encrypted_storage' / f"{sha256_hash}.zip"
            
            # Create password-protected ZIP
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                zf.setpassword(b'infected')
                zf.write(file_path, arcname=file_path.name)
            
            logger.debug(f"üîí Created encrypted backup: {zip_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Error creating encrypted backup: {e}")

    def collect_from_upload(self, 
                           uploaded_file,
                           source_ip: str,
                           attack_id: str = None,
                           request_data: Dict = None) -> Optional[Dict]:
        """
        Collect file from HTTP upload
        
        Args:
            uploaded_file: Flask/Werkzeug FileStorage object or file-like object
            source_ip: Attacker IP address
            attack_id: Associated attack log ID
            request_data: HTTP request metadata (headers, form data, etc.)
            
        Returns:
            File metadata dictionary
        """
        try:
            # Save uploaded file temporarily
            temp_path = self.quarantine_path / 'temp' / f"upload_{uuid.uuid4()}"
            temp_path.parent.mkdir(exist_ok=True)
            
            # Handle different upload types
            if hasattr(uploaded_file, 'save'):
                # Flask FileStorage
                uploaded_file.save(str(temp_path))
                original_filename = uploaded_file.filename
            else:
                # Raw file object
                with open(temp_path, 'wb') as f:
                    f.write(uploaded_file.read())
                original_filename = getattr(uploaded_file, 'name', 'unknown')
            
            # Collect the file
            metadata = self.collect_file(
                file_path=str(temp_path),
                source_ip=source_ip,
                original_filename=original_filename,
                capture_method='file_upload',
                attack_id=attack_id,
                additional_metadata={
                    'upload_info': request_data
                }
            )
            
            # Clean up temp file
            if temp_path.exists():
                temp_path.unlink()
            
            return metadata
            
        except Exception as e:
            logger.error(f"‚ùå Error collecting uploaded file: {e}")
            return None

    def collect_from_payload(self, 
                            payload_data: bytes,
                            source_ip: str,
                            payload_type: str = 'unknown',
                            attack_id: str = None,
                            context: Dict = None) -> Optional[Dict]:
        """
        Collect malware from extracted payload (shellcode, scripts, etc.)
        
        Args:
            payload_data: Raw payload bytes
            source_ip: Attacker IP
            payload_type: Type of payload (shellcode, script, encoded_binary)
            attack_id: Associated attack log ID
            context: Additional context (URL, injection point, etc.)
            
        Returns:
            File metadata dictionary
        """
        try:
            # Save payload to temp file
            temp_path = self.quarantine_path / 'temp' / f"payload_{uuid.uuid4()}.bin"
            temp_path.parent.mkdir(exist_ok=True)
            
            with open(temp_path, 'wb') as f:
                f.write(payload_data)
            
            # Collect the payload
            metadata = self.collect_file(
                file_path=str(temp_path),
                source_ip=source_ip,
                original_filename=f"{payload_type}_payload.bin",
                capture_method='payload_extraction',
                attack_id=attack_id,
                additional_metadata={
                    'payload_type': payload_type,
                    'context': context
                }
            )
            
            # Clean up temp file
            if temp_path.exists():
                temp_path.unlink()
            
            return metadata
            
        except Exception as e:
            logger.error(f"‚ùå Error collecting payload: {e}")
            return None

    def get_sample_info(self, file_id: str = None, sha256: str = None) -> Optional[Dict]:
        """
        Retrieve metadata for a collected sample
        
        Args:
            file_id: Unique file ID, or
            sha256: SHA256 hash of the file
            
        Returns:
            File metadata dictionary
        """
        try:
            if file_id:
                metadata_path = self.quarantine_path / 'metadata' / f"{file_id}.json"
                if metadata_path.exists():
                    with open(metadata_path, 'r') as f:
                        return json.load(f)
            
            if sha256:
                # Search all metadata files for matching SHA256
                metadata_dir = self.quarantine_path / 'metadata'
                for metadata_file in metadata_dir.glob('*.json'):
                    with open(metadata_file, 'r') as f:
                        metadata = json.load(f)
                        if metadata.get('hashes', {}).get('sha256') == sha256:
                            return metadata
            
            logger.warning(f"‚ö†Ô∏è  Sample not found: file_id={file_id}, sha256={sha256}")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error retrieving sample info: {e}")
            return None

    def list_samples(self, category: str = None, limit: int = 100) -> List[Dict]:
        """
        List collected malware samples
        
        Args:
            category: Filter by category (executable, script, document, etc.)
            limit: Maximum number of samples to return
            
        Returns:
            List of sample metadata dictionaries
        """
        try:
            samples = []
            metadata_dir = self.quarantine_path / 'metadata'
            
            for metadata_file in metadata_dir.glob('*.json'):
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    
                    # Filter by category if specified
                    if category and metadata.get('file_type', {}).get('category') != category:
                        continue
                    
                    samples.append(metadata)
                    
                    if len(samples) >= limit:
                        break
            
            # Sort by timestamp (newest first)
            samples.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
            
            return samples
            
        except Exception as e:
            logger.error(f"‚ùå Error listing samples: {e}")
            return []

    def get_statistics(self) -> Dict:
        """
        Get malware collection statistics
        
        Returns:
            Dictionary with statistics
        """
        try:
            metadata_dir = self.quarantine_path / 'metadata'
            
            stats = {
                'total_samples': 0,
                'by_category': {},
                'by_capture_method': {},
                'total_size_bytes': 0,
                'unique_sources': set(),
                'first_sample': None,
                'last_sample': None
            }
            
            for metadata_file in metadata_dir.glob('*.json'):
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
                    
                    stats['total_samples'] += 1
                    
                    # Count by category
                    category = metadata.get('file_type', {}).get('category', 'unknown')
                    stats['by_category'][category] = stats['by_category'].get(category, 0) + 1
                    
                    # Count by capture method
                    method = metadata.get('capture_method', 'unknown')
                    stats['by_capture_method'][method] = stats['by_capture_method'].get(method, 0) + 1
                    
                    # Total size
                    stats['total_size_bytes'] += metadata.get('file_size', 0)
                    
                    # Unique sources
                    stats['unique_sources'].add(metadata.get('source_ip'))
                    
                    # First/last sample timestamps
                    timestamp = metadata.get('timestamp')
                    if not stats['first_sample'] or timestamp < stats['first_sample']:
                        stats['first_sample'] = timestamp
                    if not stats['last_sample'] or timestamp > stats['last_sample']:
                        stats['last_sample'] = timestamp
            
            # Convert set to count
            stats['unique_sources'] = len(stats['unique_sources'])
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating statistics: {e}")
            return {}


def main():
    """Test malware collector"""
    print("Testing Malware Collector...")
    
    collector = MalwareCollector()
    
    # Get statistics
    stats = collector.get_statistics()
    print(f"\nüìä Malware Collection Statistics:")
    print(f"   Total samples: {stats.get('total_samples', 0)}")
    print(f"   Unique sources: {stats.get('unique_sources', 0)}")
    print(f"   Total size: {stats.get('total_size_bytes', 0):,} bytes")
    print(f"   Categories: {stats.get('by_category', {})}")
    
    # Example: Collect a test file (create dummy file)
    test_file = "malware_quarantine/temp/test_sample.txt"
    os.makedirs(os.path.dirname(test_file), exist_ok=True)
    with open(test_file, 'w') as f:
        f.write("This is a test malware sample (not really malware)")
    
    # Collect the test file
    metadata = collector.collect_file(
        file_path=test_file,
        source_ip="192.168.1.100",
        original_filename="malicious.txt",
        capture_method="test",
        attack_id="test-attack-001"
    )
    
    if metadata:
        print(f"\n‚úÖ Test sample collected!")
        print(f"   File ID: {metadata['file_id']}")
        print(f"   SHA256: {metadata['hashes']['sha256']}")
        print(f"   Storage: {metadata['storage_path']}")
    
    # Clean up test file
    if os.path.exists(test_file):
        os.remove(test_file)


if __name__ == "__main__":
    main()
